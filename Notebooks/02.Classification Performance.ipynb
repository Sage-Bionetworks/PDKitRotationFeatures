{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Performance of Aggregated Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import synapseclient as sc\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"cleaned_walk_features.tsv\", sep = \"\\t\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_used = [feat for feat in data.columns \n",
    "             if (\"createdOn\" not in feat) \n",
    "             and (\"window\" not in feat) \n",
    "             and (\"error\" not in feat) \n",
    "             and ('nrecords' not in feat)\n",
    "             and (\"healthCode\" not in feat) \n",
    "             and (\"gender\" not in feat) \n",
    "             and (\"PD\" not in feat) \n",
    "             and (\"age\" not in feat)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2597, 106)\n",
      "(866, 106)\n",
      "(2597,)\n",
      "(866,)\n"
     ]
    }
   ],
   "source": [
    "#Seperate train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[feat_used],\n",
    "                                                   data['PD'],\n",
    "                                                   test_size = 0.25,\n",
    "                                                   random_state = 100)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = []\n",
    "clfs.append(LogisticRegression())\n",
    "clfs.append(SVC())\n",
    "clfs.append(KNeighborsClassifier(n_neighbors=3))\n",
    "clfs.append(DecisionTreeClassifier())\n",
    "clfs.append(RandomForestClassifier(max_depth = 5, \n",
    "                                   random_state = 100, \n",
    "                                   n_estimators = 1000))\n",
    "clfs.append(GradientBoostingClassifier(max_depth = 5, \n",
    "                                       random_state = 100, \n",
    "                                       n_estimators = 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Set Performance (ROC-AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics_placeholder = {}\n",
    "model_metrics_placeholder[\"classifier\"] = []\n",
    "model_metrics_placeholder[\"cross_validation_auc_score\"] = []\n",
    "model_metrics_placeholder[\"cross_validation_std\"] = []\n",
    "model_metrics_placeholder[\"test_auc_score\"] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "LogisticRegression()\n",
      "-----------------------------------\n",
      "fit_time  mean  0.04682326316833496\n",
      "fit_time  std  0.004442435689465175\n",
      "score_time  mean  0.003454756736755371\n",
      "score_time  std  0.00039239661091942436\n",
      "test_score  mean  0.8079767773715657\n",
      "test_score  std  0.036692834019000566\n",
      "---------------------------------\n",
      "SVC()\n",
      "-----------------------------------\n",
      "fit_time  mean  0.37330658435821534\n",
      "fit_time  std  0.01628038124011398\n",
      "score_time  mean  0.03746335506439209\n",
      "score_time  std  0.0017614182680470332\n",
      "test_score  mean  0.8207411049719344\n",
      "test_score  std  0.03141403844071745\n",
      "---------------------------------\n",
      "KNeighborsClassifier(n_neighbors=3)\n",
      "-----------------------------------\n",
      "fit_time  mean  0.014847493171691895\n",
      "fit_time  std  0.0009136234136673755\n",
      "score_time  mean  0.11067192554473877\n",
      "score_time  std  0.005234460286649041\n",
      "test_score  mean  0.6974152228949655\n",
      "test_score  std  0.037933936009587554\n",
      "---------------------------------\n",
      "DecisionTreeClassifier()\n",
      "-----------------------------------\n",
      "fit_time  mean  0.20958170890808106\n",
      "fit_time  std  0.010089782832173976\n",
      "score_time  mean  0.003945827484130859\n",
      "score_time  std  0.0009371858726103149\n",
      "test_score  mean  0.6337712943616648\n",
      "test_score  std  0.03739979676137329\n",
      "---------------------------------\n",
      "RandomForestClassifier(max_depth=5, n_estimators=1000, random_state=100)\n",
      "-----------------------------------\n",
      "fit_time  mean  6.626904630661011\n",
      "fit_time  std  0.2812801970898721\n",
      "score_time  mean  0.09380414485931396\n",
      "score_time  std  0.006784990442203446\n",
      "test_score  mean  0.8096842684442198\n",
      "test_score  std  0.037654433029777196\n",
      "---------------------------------\n",
      "GradientBoostingClassifier(max_depth=5, random_state=100)\n",
      "-----------------------------------\n",
      "fit_time  mean  8.258772826194763\n",
      "fit_time  std  0.12382912626160705\n",
      "score_time  mean  0.004770350456237793\n",
      "score_time  std  0.0011845929686747168\n",
      "test_score  mean  0.8236714536086666\n",
      "test_score  std  0.02634517920157939\n"
     ]
    }
   ],
   "source": [
    "clfs = []\n",
    "clfs.append(LogisticRegression())\n",
    "clfs.append(SVC())\n",
    "clfs.append(KNeighborsClassifier(n_neighbors=3))\n",
    "clfs.append(DecisionTreeClassifier())\n",
    "clfs.append(RandomForestClassifier(max_depth = 5, \n",
    "                                   random_state = 100, \n",
    "                                   n_estimators = 1000))\n",
    "clfs.append(GradientBoostingClassifier(max_depth = 5, \n",
    "                                       random_state = 100, \n",
    "                                       n_estimators = 100))\n",
    "\n",
    "for classifier in clfs:\n",
    "    pipeline = Pipeline([\n",
    "        ('normalizer', MinMaxScaler()), \n",
    "        ('clf', classifier)])\n",
    "    \n",
    "    scores = cross_validate(pipeline, \n",
    "                            X_train, \n",
    "                            y_train,\n",
    "                            cv = 10, \n",
    "                           scoring = \"roc_auc\")\n",
    "    print('---------------------------------')\n",
    "    print(str(classifier))\n",
    "    print('-----------------------------------')\n",
    "    for key, values in scores.items():\n",
    "            print(key,' mean ', values.mean())\n",
    "            print(key,' std ', values.std())\n",
    "    \n",
    "    model_metrics_placeholder[\"classifier\"].append(type(classifier).__name__)\n",
    "    model_metrics_placeholder[\"cross_validation_auc_score\"].append(scores[\"test_score\"].mean())\n",
    "    model_metrics_placeholder[\"cross_validation_std\"].append(scores[\"test_score\"].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-set Performance (ROC-AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "LogisticRegression()\n",
      "-----------------------------------\n",
      "ROC-AUC Score on Test-Set 0.7573237597911227 \n",
      "\n",
      "---------------------------------\n",
      "SVC()\n",
      "-----------------------------------\n",
      "ROC-AUC Score on Test-Set 0.8076655294854835 \n",
      "\n",
      "---------------------------------\n",
      "KNeighborsClassifier(n_neighbors=3)\n",
      "-----------------------------------\n",
      "ROC-AUC Score on Test-Set 0.62514199935086 \n",
      "\n",
      "---------------------------------\n",
      "DecisionTreeClassifier()\n",
      "-----------------------------------\n",
      "ROC-AUC Score on Test-Set 0.6117581912561307 \n",
      "\n",
      "---------------------------------\n",
      "RandomForestClassifier(max_depth=5, n_estimators=1000, random_state=100)\n",
      "-----------------------------------\n",
      "ROC-AUC Score on Test-Set 0.8670154063479452 \n",
      "\n",
      "---------------------------------\n",
      "GradientBoostingClassifier(max_depth=5, random_state=100)\n",
      "-----------------------------------\n",
      "ROC-AUC Score on Test-Set 0.7581532277967775 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for classifier in clfs:\n",
    "    print('---------------------------------')\n",
    "    print(str(classifier))\n",
    "    print('-----------------------------------')\n",
    "    pipeline = Pipeline([\n",
    "        ('normalizer', MinMaxScaler()), \n",
    "        ('clf', classifier)])\n",
    "    auc_score = roc_auc_score(pipeline.fit(X_train, y_train).predict(X_test), y_test)\n",
    "    print(\"ROC-AUC Score on Test-Set %s \\n\"%auc_score)\n",
    "    model_metrics_placeholder[\"test_auc_score\"].append(auc_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_venv",
   "language": "python",
   "name": "test_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
